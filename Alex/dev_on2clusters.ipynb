{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.cm as cm\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#FF0B04\", \"#F1BE48\",\n",
    "           \"#B9975B\", \"#8B5B29\",\n",
    "           \"#524727\",\n",
    "         ]\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ames_Housing_Price_Data.csv', \n",
    "                             index_col=0,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = helper.data_processing_wrapper(df, num_to_cat_list=[], remove_PID=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LogSalePrice'] = np.log(train['SalePrice'])\n",
    "test['LogSalePrice'] = np.log(test['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhds = train.groupby('Neighborhood').median()[['LogSalePrice', 'GrLivArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = train.groupby('Neighborhood').count().apply(lambda x: x['PID']/len(train) ,axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "_ = scaler.fit_transform(nhds)\n",
    "clusterer = KMeans(n_clusters=2, random_state=42)\n",
    "cluster_labels = clusterer.fit_predict(_, sample_weight=weights)\n",
    "nhds['Cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = nhds['Cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blmngtn': 0,\n",
       " 'Blueste': 1,\n",
       " 'BrDale': 1,\n",
       " 'BrkSide': 1,\n",
       " 'ClearCr': 0,\n",
       " 'CollgCr': 0,\n",
       " 'Crawfor': 0,\n",
       " 'Edwards': 1,\n",
       " 'Gilbert': 0,\n",
       " 'Greens': 1,\n",
       " 'GrnHill': 0,\n",
       " 'IDOTRR': 1,\n",
       " 'Landmrk': 1,\n",
       " 'MeadowV': 1,\n",
       " 'Mitchel': 1,\n",
       " 'NAmes': 1,\n",
       " 'NPkVill': 1,\n",
       " 'NWAmes': 0,\n",
       " 'NoRidge': 0,\n",
       " 'NridgHt': 0,\n",
       " 'OldTown': 1,\n",
       " 'SWISU': 1,\n",
       " 'Sawyer': 1,\n",
       " 'SawyerW': 0,\n",
       " 'Somerst': 0,\n",
       " 'StoneBr': 0,\n",
       " 'Timber': 0,\n",
       " 'Veenker': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NhdCluster'] = train.apply(lambda x: cluster_dict[x['Neighborhood']], axis=1)\n",
    "test['NhdCluster'] = test.apply(lambda x: cluster_dict[x['Neighborhood']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_dict = train.groupby(['Neighborhood', 'BedroomAbvGr', 'BldgType',\n",
    "               'OverallQual', 'FullBath', 'KitchenQual', 'GarageCars']).mean()['LogSalePrice'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Comp'] = train.apply(lambda x: comp_dict[(x['Neighborhood'], x['BedroomAbvGr'], x['BldgType'],\n",
    "               x['OverallQual'], x['FullBath'], x['KitchenQual'], x['GarageCars'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_dict = train.groupby('Neighborhood').mean()['LogSalePrice'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_comp(x):\n",
    "    if (x['Neighborhood'], x['BedroomAbvGr'], x['BldgType'],\n",
    "               x['OverallQual'], x['FullBath'], x['KitchenQual'], x['GarageCars']) in comp_dict.keys():\n",
    "        return comp_dict[(x['Neighborhood'], x['BedroomAbvGr'], x['BldgType'],\n",
    "               x['OverallQual'], x['FullBath'], x['KitchenQual'], x['GarageCars'])]\n",
    "    else:\n",
    "        return alt_dict[x['Neighborhood']]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Comp'] = test.apply(lambda x: test_comp(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train = train.loc[train['NhdCluster']==0,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y0_train = train.loc[train['NhdCluster']==0, 'LogSalePrice']\n",
    "X0_test = test.loc[test['NhdCluster']==0,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y0_test = test.loc[test['NhdCluster']==0, 'LogSalePrice']\n",
    "X1_train = train.loc[train['NhdCluster']==1,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y1_train = train.loc[train['NhdCluster']==1, 'LogSalePrice']\n",
    "X1_test = test.loc[test['NhdCluster']==1,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y1_test = test.loc[test['NhdCluster']==1, 'LogSalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 78)\n",
      "(975, 78)\n",
      "\n",
      "\n",
      "(896,)\n",
      "(975,)\n",
      "\n",
      "\n",
      "(298, 78)\n",
      "(326, 78)\n",
      "\n",
      "\n",
      "(298,)\n",
      "(326,)\n"
     ]
    }
   ],
   "source": [
    "print(X0_train.shape)\n",
    "print(X1_train.shape)\n",
    "print('\\n')\n",
    "print(y0_train.shape)\n",
    "print(y1_train.shape)\n",
    "print('\\n')\n",
    "print(X0_test.shape)\n",
    "print(X1_test.shape)\n",
    "print('\\n')\n",
    "print(y0_test.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [col for col in train.select_dtypes(['object','bool']).columns.to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_select(X, y, alpha):\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X = pipe.fit_transform(X)\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    cross = cross_val_score(Lasso(alpha=alpha, max_iter=5000), X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    selector = SelectFromModel(Lasso(alpha=alpha, max_iter=5000))\n",
    "    selector.fit(X,y)\n",
    "    num_features = np.sum(selector.get_support())\n",
    "    \n",
    "    return cross, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.93582159, 0.92170681, 0.90819949, 0.91748462, 0.92919149]), 176)\n",
      "(array([0.9401505 , 0.92864602, 0.93188967, 0.92251967, 0.9328494 ]), 171)\n",
      "(array([0.94766238, 0.94649344, 0.96010202, 0.93743509, 0.94743315]), 128)\n",
      "(array([0.92941194, 0.93696296, 0.95319408, 0.9221803 , 0.93095869]), 18)\n",
      "(array([0.79241641, 0.79835925, 0.81870352, 0.81475369, 0.77936599]), 1)\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.logspace(-5, -1, 5):\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.93247107, 0.9395738 , 0.95584961, 0.92504159, 0.93555944]), 23)\n",
      "(array([0.93111083, 0.93827466, 0.95457951, 0.92373417, 0.93331234]), 20)\n",
      "(array([0.92941194, 0.93696296, 0.95319408, 0.9221803 , 0.93095869]), 18)\n",
      "(array([0.91308236, 0.92398364, 0.93863707, 0.91083771, 0.90999924]), 6)\n",
      "(array([0.90206943, 0.91264229, 0.92960934, 0.90314976, 0.89389083]), 4)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.008, 0.009, 0.01, 0.02, 0.03]:\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.93032781, 0.93764108, 0.95384918, 0.92298488, 0.93211195]), 18)\n",
      "(array([0.93014658, 0.93750867, 0.95371241, 0.92283178, 0.93187116]), 18)\n",
      "(array([0.92996385, 0.93737434, 0.95358514, 0.92267327, 0.93164837]), 18)\n",
      "(array([0.92978509, 0.93724124, 0.95345907, 0.92251251, 0.93142023]), 18)\n",
      "(array([0.92959927, 0.93710306, 0.95332746, 0.92234948, 0.93119037]), 18)\n",
      "(array([0.92941194, 0.93696296, 0.95319408, 0.9221803 , 0.93095869]), 18)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0095, 0.0096, 0.0097, 0.0098, 0.0099, 0.01]:\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclude 18 features is a good number for cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91450697, 0.92583915, 0.90804242, 0.92196817, 0.90714173]), 198)\n",
      "(array([0.91663698, 0.93090324, 0.90961465, 0.92486307, 0.90933012]), 187)\n",
      "(array([0.9220213 , 0.94236536, 0.91436338, 0.9370649 , 0.91458517]), 127)\n",
      "(array([0.91885627, 0.91882881, 0.89608037, 0.93120482, 0.90748764]), 13)\n",
      "(array([0.77716399, 0.77494101, 0.77344229, 0.78972065, 0.76185294]), 1)\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.logspace(-5, -1, 5):\n",
    "    print(Lasso_select(X1_train,y1_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.9207557 , 0.92438973, 0.90010139, 0.93372401, 0.91037727]), 14)\n",
      "(array([0.91988094, 0.92169996, 0.89814723, 0.93250621, 0.90889565]), 13)\n",
      "(array([0.91885627, 0.91882881, 0.89608037, 0.93120482, 0.90748764]), 13)\n",
      "(array([0.91003181, 0.9016044 , 0.88007828, 0.92248211, 0.89348594]), 4)\n",
      "(array([0.90388038, 0.89406663, 0.8743715 , 0.91647788, 0.88592663]), 1)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.008, 0.009, 0.01, 0.02, 0.03]:\n",
    "    print(Lasso_select(X1_train,y1_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.92091136, 0.92487355, 0.90045318, 0.93395117, 0.91065072]), 16)\n",
      "(array([0.92083469, 0.92463605, 0.90027662, 0.9338405 , 0.9105156 ]), 15)\n",
      "(array([0.9207557 , 0.92438973, 0.90010139, 0.93372401, 0.91037727]), 14)\n",
      "(array([0.92067603, 0.92414046, 0.89992317, 0.93360991, 0.91023573]), 14)\n",
      "(array([0.92059382, 0.92388838, 0.89974187, 0.93349405, 0.91009099]), 14)\n",
      "(array([0.92051029, 0.92362936, 0.89955375, 0.93337661, 0.90994211]), 14)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0078, 0.0079, 0.008, 0.0081, 0.0082, 0.0083]:\n",
    "    print(Lasso_select(X1_train,y1_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.92136314, 0.92606637, 0.90126985, 0.93460294, 0.91128054]), 18)\n",
      "(array([0.92125095, 0.92580219, 0.90111264, 0.93443999, 0.91116003]), 18)\n",
      "(array([0.9211432 , 0.92557029, 0.90095234, 0.9342978 , 0.91103763]), 17)\n",
      "(array([0.92106101, 0.92534075, 0.90078892, 0.93417413, 0.91091138]), 17)\n",
      "(array([0.92098669, 0.92510847, 0.9006226 , 0.93406372, 0.91078265]), 17)\n",
      "(array([0.92091136, 0.92487355, 0.90045318, 0.93395117, 0.91065072]), 16)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0073, 0.0074, 0.0075, 0.0076, 0.0077, 0.0078]:\n",
    "    print(Lasso_select(X1_train,y1_train,alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclude 18 features might be a good number for both clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x11_2Story',\n",
       " 'Cat__x27_New',\n",
       " 'OverallQual',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'BsmtFinSF1',\n",
       " 'HeatingQC',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'BsmtFullBath',\n",
       " 'HalfBath',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageArea',\n",
       " 'OpenPorchSF',\n",
       " 'Comp']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "X = pipe.fit_transform(X0_train)\n",
    "y = y0_train\n",
    "\n",
    "selector = SelectFromModel(Lasso(alpha=0.0095, max_iter=5000))\n",
    "selector.fit(X,y)\n",
    "mask = selector.get_support()\n",
    "feat_names = pipe.named_steps['transformer'].get_feature_names()\n",
    "names0 = [name for name, boo in zip(feat_names, mask) if boo]\n",
    "names0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x11_1Story',\n",
       " 'Cat__x14_BrkFace',\n",
       " 'Cat__x18_None',\n",
       " 'OverallCond',\n",
       " 'YearRemodAdd',\n",
       " 'BsmtQual',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " '1stFlrSF',\n",
       " 'BsmtFullBath',\n",
       " 'HalfBath',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageArea',\n",
       " 'WoodDeckSF',\n",
       " 'ScreenPorch',\n",
       " 'Comp']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "X = pipe.fit_transform(X1_train)\n",
    "y = y1_train\n",
    "\n",
    "selector = SelectFromModel(Lasso(alpha=0.0073, max_iter=5000))\n",
    "selector.fit(X,y)\n",
    "mask = selector.get_support()\n",
    "feat_names = pipe.named_steps['transformer'].get_feature_names()\n",
    "names1 = [name for name, boo in zip(feat_names, mask) if boo]\n",
    "names1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'MSZoning',\n",
       " 1: 'Street',\n",
       " 2: 'LotShape',\n",
       " 3: 'LandContour',\n",
       " 4: 'Utilities',\n",
       " 5: 'LotConfig',\n",
       " 6: 'LandSlope',\n",
       " 7: 'Neighborhood',\n",
       " 8: 'Condition1',\n",
       " 9: 'Condition2',\n",
       " 10: 'BldgType',\n",
       " 11: 'HouseStyle',\n",
       " 12: 'RoofStyle',\n",
       " 13: 'RoofMatl',\n",
       " 14: 'Exterior1st',\n",
       " 15: 'Exterior2nd',\n",
       " 16: 'MasVnrType',\n",
       " 17: 'Foundation',\n",
       " 18: 'BsmtFinType1',\n",
       " 19: 'BsmtFinType2',\n",
       " 20: 'Heating',\n",
       " 21: 'CentralAir',\n",
       " 22: 'Electrical',\n",
       " 23: 'Functional',\n",
       " 24: 'GarageType',\n",
       " 25: 'Fence',\n",
       " 26: 'MiscFeature',\n",
       " 27: 'SaleType',\n",
       " 28: 'SaleCondition'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(enumerate(categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "select0 = ['HouseStyle',\n",
    " 'SaleType',\n",
    " 'OverallQual',\n",
    " 'YearRemodAdd',\n",
    " 'MasVnrArea',\n",
    " 'ExterQual',\n",
    " 'BsmtFinSF1',\n",
    " 'HeatingQC',\n",
    " '1stFlrSF',\n",
    " '2ndFlrSF',\n",
    " 'BsmtFullBath',\n",
    " 'HalfBath',\n",
    " 'TotRmsAbvGrd',\n",
    " 'Fireplaces',\n",
    " 'FireplaceQu',\n",
    " 'GarageArea',\n",
    " 'OpenPorchSF',\n",
    " 'Comp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats0 = [col for col in select0 if col in categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9435184  0.94352135 0.94354421 0.94344473]\n",
      "{'ridge__alpha': 1}\n",
      "0.9435442106806213\n"
     ]
    }
   ],
   "source": [
    "X = X0_train[select0]\n",
    "y = y0_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats0)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94353239 0.94353356 0.9435347  0.94353583 0.94353694 0.94353803\n",
      " 0.94353911 0.94354016 0.9435412  0.94354222 0.94354323 0.94354421\n",
      " 0.94354518 0.94354613 0.94354706 0.94354797 0.94354887 0.94354975\n",
      " 0.94355061 0.94355146 0.94355229 0.9435531  0.94355389 0.94355467\n",
      " 0.94355542 0.94355617 0.94355689 0.9435576  0.94355829 0.94355896\n",
      " 0.94355962 0.94356026 0.94356089 0.94356149 0.94356208 0.94356266\n",
      " 0.94356321 0.94356375 0.94356428 0.94356478 0.94356528 0.94356575\n",
      " 0.94356621 0.94356665 0.94356708 0.94356749 0.94356788 0.94356826\n",
      " 0.94356862 0.94356897 0.94356929 0.94356961 0.94356991 0.94357019\n",
      " 0.94357045 0.9435707  0.94357094 0.94357116 0.94357136 0.94357155\n",
      " 0.94357172 0.94357188 0.94357202 0.94357215 0.94357226 0.94357235\n",
      " 0.94357243 0.9435725  0.94357255 0.94357258 0.9435726  0.9435726\n",
      " 0.94357259 0.94357257 0.94357252 0.94357247 0.9435724  0.94357231\n",
      " 0.94357221 0.9435721  0.94357197 0.94357182 0.94357166 0.94357149\n",
      " 0.9435713  0.9435711  0.94357088 0.94357065 0.9435704  0.94357014\n",
      " 0.94356986 0.94356957 0.94356927 0.94356895 0.94356862 0.94356827\n",
      " 0.94356791 0.94356754 0.94356715 0.94356675]\n",
      "{'ridge__alpha': 3.7272727272727275}\n",
      "0.9435726025794222\n"
     ]
    }
   ],
   "source": [
    "X = X0_train[select0]\n",
    "y = y0_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats0)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':np.linspace(0.5, 5, 100)}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha of 3.73 looks good for cluster 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "select1 = ['HouseStyle',\n",
    " 'Exterior1st',\n",
    " 'BsmtFinType1',\n",
    " 'OverallCond',\n",
    " 'YearRemodAdd',\n",
    " 'BsmtQual',\n",
    " 'BsmtExposure',\n",
    " 'BsmtFinSF1',\n",
    " '1stFlrSF',\n",
    " 'BsmtFullBath',\n",
    " 'HalfBath',\n",
    " 'TotRmsAbvGrd',\n",
    " 'Fireplaces',\n",
    " 'FireplaceQu',\n",
    " 'GarageArea',\n",
    " 'WoodDeckSF',\n",
    " 'ScreenPorch',\n",
    " 'Comp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats1 = [col for col in select1 if col in categorical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92584317 0.92584624 0.92587134 0.9258704 ]\n",
      "{'ridge__alpha': 1}\n",
      "0.9258713394620706\n"
     ]
    }
   ],
   "source": [
    "X = X1_train[select1]\n",
    "y = y1_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats1)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92590939 0.92590952 0.92590966 0.92590979 0.92590991 0.92591004\n",
      " 0.92591017 0.9259103  0.92591043 0.92591055 0.92591068 0.92591081\n",
      " 0.92591093 0.92591105 0.92591118 0.9259113  0.92591142 0.92591155\n",
      " 0.92591167 0.92591179 0.92591191 0.92591203 0.92591215 0.92591227\n",
      " 0.92591238 0.9259125  0.92591262 0.92591273 0.92591285 0.92591296\n",
      " 0.92591308 0.92591319 0.92591331 0.92591342 0.92591353 0.92591364\n",
      " 0.92591375 0.92591386 0.92591397 0.92591408 0.92591419 0.9259143\n",
      " 0.92591441 0.92591452 0.92591462 0.92591473 0.92591483 0.92591494\n",
      " 0.92591504 0.92591515 0.92591525 0.92591535 0.92591545 0.92591555\n",
      " 0.92591566 0.92591576 0.92591586 0.92591595 0.92591605 0.92591615\n",
      " 0.92591625 0.92591634 0.92591644 0.92591654 0.92591663 0.92591673\n",
      " 0.92591682 0.92591691 0.92591701 0.9259171  0.92591719 0.92591728\n",
      " 0.92591737 0.92591746 0.92591755 0.92591764 0.92591773 0.92591782\n",
      " 0.9259179  0.92591799 0.92591808 0.92591816 0.92591825 0.92591833\n",
      " 0.92591841 0.9259185  0.92591858 0.92591866 0.92591874 0.92591883\n",
      " 0.92591891 0.92591899 0.92591906 0.92591914 0.92591922 0.9259193\n",
      " 0.92591938 0.92591945 0.92591953 0.9259196  0.92591968 0.92591975\n",
      " 0.92591983 0.9259199  0.92591997 0.92592004 0.92592012 0.92592019\n",
      " 0.92592026 0.92592033 0.9259204  0.92592046 0.92592053 0.9259206\n",
      " 0.92592067 0.92592073 0.9259208  0.92592086 0.92592093 0.92592099\n",
      " 0.92592106 0.92592112 0.92592118 0.92592124 0.92592131 0.92592137\n",
      " 0.92592143 0.92592149 0.92592155 0.9259216  0.92592166 0.92592172\n",
      " 0.92592178 0.92592183 0.92592189 0.92592194 0.925922   0.92592205\n",
      " 0.92592211 0.92592216 0.92592221 0.92592226 0.92592232 0.92592237\n",
      " 0.92592242 0.92592247 0.92592252 0.92592256 0.92592261 0.92592266\n",
      " 0.92592271 0.92592275 0.9259228  0.92592284 0.92592289 0.92592293\n",
      " 0.92592298 0.92592302 0.92592306 0.92592311 0.92592315 0.92592319\n",
      " 0.92592323 0.92592327 0.92592331 0.92592335 0.92592338 0.92592342\n",
      " 0.92592346 0.9259235  0.92592353 0.92592357 0.9259236  0.92592364\n",
      " 0.92592367 0.9259237  0.92592374 0.92592377 0.9259238  0.92592383\n",
      " 0.92592386 0.92592389 0.92592392 0.92592395 0.92592398 0.92592401\n",
      " 0.92592403 0.92592406 0.92592409 0.92592411 0.92592414 0.92592416\n",
      " 0.92592419 0.92592421 0.92592423 0.92592425 0.92592428 0.9259243\n",
      " 0.92592432 0.92592434 0.92592436 0.92592438 0.9259244  0.92592441\n",
      " 0.92592443 0.92592445 0.92592446 0.92592448 0.9259245  0.92592451\n",
      " 0.92592453 0.92592454 0.92592455 0.92592456 0.92592458 0.92592459\n",
      " 0.9259246  0.92592461 0.92592462 0.92592463 0.92592464 0.92592465\n",
      " 0.92592465 0.92592466 0.92592467 0.92592467 0.92592468 0.92592468\n",
      " 0.92592469 0.92592469 0.9259247  0.9259247  0.9259247  0.9259247\n",
      " 0.92592471 0.92592471 0.92592471 0.92592471 0.92592471 0.9259247\n",
      " 0.9259247  0.9259247  0.9259247  0.92592469 0.92592469 0.92592469\n",
      " 0.92592468 0.92592467 0.92592467 0.92592466 0.92592465 0.92592465\n",
      " 0.92592464 0.92592463 0.92592462 0.92592461 0.9259246  0.92592459\n",
      " 0.92592458 0.92592457 0.92592455 0.92592454 0.92592453 0.92592451\n",
      " 0.9259245  0.92592448 0.92592447 0.92592445 0.92592443 0.92592442\n",
      " 0.9259244  0.92592438 0.92592436 0.92592434 0.92592432 0.9259243\n",
      " 0.92592428 0.92592426 0.92592424 0.92592422 0.92592419 0.92592417\n",
      " 0.92592414 0.92592412 0.92592409 0.92592407 0.92592404 0.92592402\n",
      " 0.92592399 0.92592396 0.92592393 0.9259239  0.92592387 0.92592384\n",
      " 0.92592381 0.92592378 0.92592375 0.92592372 0.92592369 0.92592365\n",
      " 0.92592362 0.92592359 0.92592355 0.92592352 0.92592348 0.92592344\n",
      " 0.92592341 0.92592337 0.92592333 0.92592329 0.92592325 0.92592322\n",
      " 0.92592318 0.92592314 0.92592309 0.92592305 0.92592301 0.92592297\n",
      " 0.92592293 0.92592288 0.92592284 0.92592279 0.92592275 0.9259227\n",
      " 0.92592266 0.92592261 0.92592256 0.92592252 0.92592247 0.92592242\n",
      " 0.92592237 0.92592232 0.92592227 0.92592222 0.92592217 0.92592212\n",
      " 0.92592206 0.92592201 0.92592196 0.9259219  0.92592185 0.92592179\n",
      " 0.92592174 0.92592168 0.92592163 0.92592157 0.92592151 0.92592145\n",
      " 0.92592139 0.92592134 0.92592128 0.92592122 0.92592115 0.92592109\n",
      " 0.92592103 0.92592097 0.92592091 0.92592084 0.92592078 0.92592072\n",
      " 0.92592065 0.92592059 0.92592052 0.92592045 0.92592039 0.92592032\n",
      " 0.92592025 0.92592018 0.92592012 0.92592005 0.92591998 0.92591991\n",
      " 0.92591984 0.92591976 0.92591969 0.92591962 0.92591955 0.92591947\n",
      " 0.9259194  0.92591932 0.92591925 0.92591917 0.9259191  0.92591902\n",
      " 0.92591895 0.92591887 0.92591879 0.92591871 0.92591863 0.92591855\n",
      " 0.92591847 0.92591839 0.92591831 0.92591823 0.92591815 0.92591806\n",
      " 0.92591798 0.9259179  0.92591781 0.92591773]\n",
      "{'ridge__alpha': 5.365914786967418}\n",
      "0.9259247068052886\n"
     ]
    }
   ],
   "source": [
    "X = X1_train[select1]\n",
    "y = y1_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats1)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':np.linspace(3, 7, 400)}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.cv_results_['mean_test_score'])\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha of 5.37 looks good for cluster 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now putting it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_tr = X0_train[select0]\n",
    "X0_ts = X0_test[select0]\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats0)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge(alpha=3.73))])\n",
    "\n",
    "pipe.fit(X0_tr, y0_train)\n",
    "\n",
    "cluster0_train_predict = pipe.predict(X0_tr)\n",
    "cluster0_test_predict = pipe.predict(X0_ts)\n",
    "\n",
    "X1_tr = X1_train[select1]\n",
    "X1_ts = X1_test[select1]\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), cats1)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('ridge', Ridge(alpha=5.37))])\n",
    "\n",
    "pipe.fit(X1_tr, y1_train)\n",
    "\n",
    "cluster1_train_predict = pipe.predict(X1_tr)\n",
    "cluster1_test_predict = pipe.predict(X1_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0_train_predict = pd.DataFrame(cluster0_train_predict).rename(columns={0:'prediction'})\n",
    "cluster1_train_predict = pd.DataFrame(cluster1_train_predict).rename(columns={0:'prediction'})\n",
    "cluster0_test_predict = pd.DataFrame(cluster0_test_predict).rename(columns={0:'prediction'})\n",
    "cluster1_test_predict = pd.DataFrame(cluster1_test_predict).rename(columns={0:'prediction'})\n",
    "\n",
    "train_predict = pd.concat([cluster0_train_predict, cluster1_train_predict])\n",
    "test_predict = pd.concat([cluster0_test_predict, cluster1_test_predict])\n",
    "train_target = pd.concat([y0_train, y1_train])\n",
    "test_target = pd.concat([y0_test, y1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871\n",
      "624\n",
      "1871\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "print(len(train_predict))\n",
    "print(len(test_predict))\n",
    "print(len(train_target))\n",
    "print(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is 0.9651636892887285\n",
      "Test score is 0.8304349654373213\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score is {r2_score(train_target, train_predict)}')\n",
    "print(f'Test score is {r2_score(test_target, test_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 train score is 0.9485168704918534\n",
      "Cluster 0 test score is 0.8376971388950912\n",
      "\n",
      "\n",
      "Cluster 1 train score is 0.9323360372676686\n",
      "Cluster 1 test score is 0.5420071689880459\n"
     ]
    }
   ],
   "source": [
    "print(f'Cluster 0 train score is {r2_score(y0_train, cluster0_train_predict)}')\n",
    "print(f'Cluster 0 test score is {r2_score(y0_test, cluster0_test_predict)}')\n",
    "print('\\n')\n",
    "print(f'Cluster 1 train score is {r2_score(y1_train, cluster1_train_predict)}')\n",
    "print(f'Cluster 1 test score is {r2_score(y1_test, cluster1_test_predict)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
