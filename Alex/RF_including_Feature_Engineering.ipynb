{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF including Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper import * \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and clean with wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "housing = pd.read_csv('Ames_Housing_Price_Data.csv', index_col=0,low_memory = False)\n",
    "# data processing\n",
    "train, test = data_processing_wrapper(housing,\n",
    "                                               num_to_cat_list = ['MSSubClass','MoSold'],\n",
    "                                             remove_PID = False\n",
    "                                        )\n",
    "\n",
    "# feature engineering wrapper\n",
    "train, test = feature_engineering_wrapper(train, test)\n",
    "\n",
    "# importing school feature\n",
    "schools = pd.read_csv('schoolFeatures.csv',index_col = 0)\n",
    "school_keep = [\n",
    "    'PID',\n",
    "    'closestSchool'\n",
    "]\n",
    "schools = schools[school_keep]\n",
    "\n",
    "# merge school feature onto original data set.\n",
    "train = train.merge(schools, how = 'left', left_on = 'PID', right_on = 'PID')\n",
    "test = test.merge(schools, how = 'left', left_on = 'PID', right_on = 'PID')\n",
    "\n",
    "train = train.dropna(subset=['closestSchool'])\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "test = test.dropna(subset=['closestSchool'])\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing started out with 81 columns (2580 rows)\n",
    "#feature engineering - ended up with 129 columns (including PID and SalePrice)-- (added 48 new columns) (2477 rows between train and test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train.copy()\n",
    "test_raw = test.copy()\n",
    "\n",
    "train_X = train_raw.drop(['SalePrice','PID'],axis='columns')\n",
    "train_y = np.log(train_raw['SalePrice'])\n",
    "test_X = test_raw.drop(['SalePrice','PID'],axis='columns')\n",
    "test_y = np.log(test_raw['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_log = train_y.rename('LogSalePrice')\n",
    "test_y_log = test_y.rename('LogSalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = train_X.select_dtypes(['object']).columns.to_list()\n",
    "num_feats = train_X.select_dtypes(['int64','float64']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(cat_feats))\n",
    "print(len(num_feats))\n",
    "len(train_X.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'), dtype('float64'), dtype('O')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GrLivArea                   int64\n",
       "LotArea                     int64\n",
       "Alley                       int64\n",
       "OverallQual                 int64\n",
       "OverallCond                 int64\n",
       "YearBuilt                   int64\n",
       "YearRemodAdd                int64\n",
       "ExterQual                   int64\n",
       "ExterCond                   int64\n",
       "BsmtQual                    int64\n",
       "BsmtCond                    int64\n",
       "BsmtExposure                int64\n",
       "HeatingQC                   int64\n",
       "1stFlrSF                    int64\n",
       "2ndFlrSF                    int64\n",
       "LowQualFinSF                int64\n",
       "FullBath                    int64\n",
       "HalfBath                    int64\n",
       "BedroomAbvGr                int64\n",
       "KitchenAbvGr                int64\n",
       "KitchenQual                 int64\n",
       "TotRmsAbvGrd                int64\n",
       "Fireplaces                  int64\n",
       "FireplaceQu                 int64\n",
       "GarageFinish                int64\n",
       "GarageQual                  int64\n",
       "GarageCond                  int64\n",
       "PavedDrive                  int64\n",
       "WoodDeckSF                  int64\n",
       "OpenPorchSF                 int64\n",
       "EnclosedPorch               int64\n",
       "3SsnPorch                   int64\n",
       "ScreenPorch                 int64\n",
       "PoolArea                    int64\n",
       "PoolQC                      int64\n",
       "MiscVal                     int64\n",
       "YrSold                      int64\n",
       "year_since_built            int64\n",
       "year_since_remod            int64\n",
       "overall_score               int64\n",
       "exter_score                 int64\n",
       "bsmt_score                  int64\n",
       "garage_score                int64\n",
       "total_deck_sf               int64\n",
       "OverallQual_squared         int64\n",
       "OverallQual_cubed           int64\n",
       "overall_score_squared       int64\n",
       "overall_score_cubed         int64\n",
       "GrLivArea_squared           int64\n",
       "GrLivArea_cubed             int64\n",
       "year_since_built_squared    int64\n",
       "year_since_built_cubed      int64\n",
       "LotArea_squared             int64\n",
       "LotArea_cubed               int64\n",
       "year_since_remod_squared    int64\n",
       "year_since_remod_cubed      int64\n",
       "BsmtExposure_squared        int64\n",
       "BsmtExposure_cubed          int64\n",
       "KitchenQual_squared         int64\n",
       "KitchenQual_cubed           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_cols = [col for col in train_X.columns.to_list() if ((col not in cat_feats) and (col not in num_feats))]\n",
    "train_X[odd_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_feats) # 32 categorical features (43 originally in housing dataset)\n",
    "len(num_feats) #95 numeric features (38 originally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing / Dummification\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('tf1',OneHotEncoder(sparse=False, handle_unknown='ignore'), cat_feats)],remainder='passthrough')\n",
    "\n",
    "train_X_transformed = preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one-hot encoded column names \n",
    "columns_transformed = preprocessor.named_transformers_['tf1'].get_feature_names(input_features= cat_feats)\n",
    "new_columns = list(columns_transformed)+num_feats\n",
    "\n",
    "#Place one-hot encoded train X into dataframe \n",
    "train_X_transformed = pd.DataFrame(train_X_transformed,columns=new_columns)\n",
    "\n",
    "#Repeat for test X \n",
    "test_X_transformed = preprocessor.transform(test_X)\n",
    "test_X_transformed = pd.DataFrame(test_X_transformed,columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter down Features Based off of LASSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selected by LASSO model (non-zero coefficients)\n",
    "coef_df = pd.read_csv('lasso_coef.csv',index_col=0) #Hayden shared this on Slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(coef_df['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of LASSO selected features: '+ str(len(selected_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of total features after preprocessing: ' + str(len(train_X_transformed.columns.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter dataframes down to the select_features \n",
    "train_X= train_X_transformed[selected_features]\n",
    "test_X = test_X_transformed[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(train_X, train_y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Cross Val score: ', cross_val_score(rf, train_X, train_y_log, cv=3))\n",
    "print('Cross Val score mean: ', cross_val_score(rf, train_X, train_y_log, cv=3).mean())\n",
    "print('Train score: ',rf.score(train_X,train_y_log))\n",
    "print('Test score: ',rf.score(test_X,test_y_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. With Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100,200,400,600,1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = list(range(10,140,20)) + ['auto','sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = list(range(10,111,10)) + ['None']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
