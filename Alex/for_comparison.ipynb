{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.cm as cm\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#FF0B04\", \"#F1BE48\",\n",
    "           \"#B9975B\", \"#8B5B29\",\n",
    "           \"#524727\",\n",
    "         ]\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ames_Housing_Price_Data.csv', \n",
    "                             index_col=0,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = helper.data_processing_wrapper(df, num_to_cat_list=[], remove_PID=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LogSalePrice'] = np.log(train['SalePrice'])\n",
    "test['LogSalePrice'] = np.log(test['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train.select_dtypes(['object','bool']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea'], axis=1)\n",
    "y_train = train['LogSalePrice']\n",
    "X_test = test.drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea'], axis=1)\n",
    "y_test = test['LogSalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note we are keeping various features related to the sale. The justification of some is clearer than others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We first build a single basic model to be trained on all of X_train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (all) Lasso for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_select(X, y, alpha):\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X = pipe.fit_transform(X)\n",
    "\n",
    "    cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "    cross = cross_val_score(Lasso(alpha=alpha, max_iter=5000), X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    selector = SelectFromModel(Lasso(alpha=alpha, max_iter=5000))\n",
    "    selector.fit(X,y)\n",
    "    num_features = np.sum(selector.get_support())\n",
    "    \n",
    "    return cross, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.93126349, 0.91993158, 0.93507105, 0.94147087]), 217)\n",
      "(array([0.93221843, 0.92667699, 0.93687772, 0.94177989]), 204)\n",
      "(array([0.93793251, 0.93477841, 0.94416997, 0.94436756]), 150)\n",
      "(array([0.91648923, 0.91656477, 0.9321301 , 0.92995493]), 44)\n",
      "(array([0.67913054, 0.69680002, 0.70571302, 0.7043804 ]), 6)\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.logspace(-5, -1, 5):\n",
    "    print(Lasso_select(X_train, y_train, alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.92854759, 0.92693649, 0.94027579, 0.93824267]), 63)\n",
      "(array([0.92803659, 0.92643237, 0.93995957, 0.9378606 ]), 61)\n",
      "(array([0.92750585, 0.92591258, 0.93964194, 0.93749254]), 58)\n",
      "(array([0.92695612, 0.9253717 , 0.93932038, 0.93713178]), 56)\n",
      "(array([0.92638571, 0.9248221 , 0.93899835, 0.93675714]), 55)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.006, 0.0062, 0.0064, 0.0066, 0.0068]:\n",
    "    print(Lasso_select(X_train,y_train,alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (all) We will try to keep the number of features below 60 so let's move ahead with Lasso_alpha = 0.0064."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are those features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x0_C (all)',\n",
       " 'Cat__x0_RM',\n",
       " 'Cat__x2_Reg',\n",
       " 'Cat__x7_ClearCr',\n",
       " 'Cat__x7_Crawfor',\n",
       " 'Cat__x7_Edwards',\n",
       " 'Cat__x7_GrnHill',\n",
       " 'Cat__x7_MeadowV',\n",
       " 'Cat__x7_NoRidge',\n",
       " 'Cat__x7_StoneBr',\n",
       " 'Cat__x8_Norm',\n",
       " 'Cat__x10_1Fam',\n",
       " 'Cat__x10_Twnhs',\n",
       " 'Cat__x14_BrkFace',\n",
       " 'Cat__x14_PreCast',\n",
       " 'Cat__x17_PConc',\n",
       " 'Cat__x21_N',\n",
       " 'Cat__x23_Typ',\n",
       " 'Cat__x28_Normal',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'BsmtQual',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " 'HeatingQC',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'BsmtFullBath',\n",
       " 'HalfBath',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageFinish',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'PavedDrive',\n",
       " 'ScreenPorch']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "X = pipe.fit_transform(X_train)\n",
    "y = y_train\n",
    "\n",
    "selector = SelectFromModel(Lasso(alpha=0.01, max_iter=5000))\n",
    "selector.fit(X,y)\n",
    "mask = selector.get_support()\n",
    "feat_names = pipe.named_steps['transformer'].get_feature_names()\n",
    "names = [name for name, boo in zip(feat_names, mask) if boo]\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (all) Train a Ridge regression on the selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 0.001}\n",
      "0.9383125666822049\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 1e-06}\n",
      "0.938312581078951\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.000001, 0.00001, 0.0001, 0.001]}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model does not find a Ridge penalty useful. We will try Lasso instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.001}\n",
      "0.9385903006865761\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "\n",
    "param_grid = {'lasso__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.001}\n",
      "0.9385903006865761\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "\n",
    "param_grid = {'lasso__alpha':[0.000001, 0.00001, 0.0001, 0.001]}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.00119009009009009}\n",
      "0.9385980623449289\n"
     ]
    }
   ],
   "source": [
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "\n",
    "param_grid = {'lasso__alpha':np.linspace(0.0001, 0.01, 1000)}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The gridsearch has selected a Lasso penalty with alpha=0.0012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now evaluate the chosen model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train score is 0.9470352051499253\n",
      "The test score is 0.9109436400780235\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.0064, max_iter=10000))),\n",
    "                 ('lasso', Lasso(alpha=0.0012))])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "print(f'The train score is {pipe.score(X_train, y_train)}')\n",
    "print(f'The test score is {pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This represents a sensible baseline. A Lasso model with 58 features (after one-hot encoding) and no engineering has a test score of 91.1%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
