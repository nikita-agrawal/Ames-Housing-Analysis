{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.cm as cm\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#FF0B04\", \"#F1BE48\",\n",
    "           \"#B9975B\", \"#8B5B29\",\n",
    "           \"#524727\",\n",
    "         ]\n",
    "sns.set_palette(sns.color_palette(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Ames_Housing_Price_Data.csv', \n",
    "                             index_col=0,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = helper.data_processing_wrapper(df, num_to_cat_list=[], remove_PID=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LogSalePrice'] = np.log(train['SalePrice'])\n",
    "test['LogSalePrice'] = np.log(test['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhds = train.groupby('Neighborhood').median()[['LogSalePrice', 'GrLivArea']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = train.groupby('Neighborhood').count().apply(lambda x: x['PID']/len(train) ,axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "_ = scaler.fit_transform(nhds)\n",
    "clusterer = KMeans(n_clusters=2, random_state=42)\n",
    "cluster_labels = clusterer.fit_predict(_, sample_weight=weights)\n",
    "nhds['Cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = nhds['Cluster'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NhdCluster'] = train.apply(lambda x: cluster_dict[x['Neighborhood']], axis=1)\n",
    "test['NhdCluster'] = test.apply(lambda x: cluster_dict[x['Neighborhood']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train = train.loc[train['NhdCluster']==0,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y0_train = train.loc[train['NhdCluster']==0, 'LogSalePrice']\n",
    "X0_test = test.loc[test['NhdCluster']==0,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y0_test = test.loc[test['NhdCluster']==0, 'LogSalePrice']\n",
    "X1_train = train.loc[train['NhdCluster']==1,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y1_train = train.loc[train['NhdCluster']==1, 'LogSalePrice']\n",
    "X1_test = test.loc[test['NhdCluster']==1,:].drop(['SalePrice', 'LogSalePrice', 'PID', 'TotalBsmtSF', 'GrLivArea', 'NhdCluster'], axis=1)\n",
    "y1_test = test.loc[test['NhdCluster']==1, 'LogSalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 77)\n",
      "(975, 77)\n",
      "\n",
      "\n",
      "(896,)\n",
      "(975,)\n",
      "\n",
      "\n",
      "(298, 77)\n",
      "(326, 77)\n",
      "\n",
      "\n",
      "(298,)\n",
      "(326,)\n"
     ]
    }
   ],
   "source": [
    "print(X0_train.shape)\n",
    "print(X1_train.shape)\n",
    "print('\\n')\n",
    "print(y0_train.shape)\n",
    "print(y1_train.shape)\n",
    "print('\\n')\n",
    "print(X0_test.shape)\n",
    "print(X1_test.shape)\n",
    "print('\\n')\n",
    "print(y0_test.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = train.select_dtypes(['object','bool']).columns.to_list() + ['MSSubClass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso for selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lasso_select(X, y, alpha):\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler(with_mean=False))\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    X = pipe.fit_transform(X)\n",
    "\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    cross = cross_val_score(Lasso(alpha=alpha, max_iter=10000), X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    selector = SelectFromModel(Lasso(alpha=alpha, max_iter=10000))\n",
    "    selector.fit(X,y)\n",
    "    num_features = np.sum(selector.get_support())\n",
    "    \n",
    "    return cross, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91746146, 0.87232791, 0.87758721, 0.88191031, 0.90808885]), 186)\n",
      "(array([0.92382067, 0.88849718, 0.90373531, 0.88969178, 0.9104986 ]), 181)\n",
      "(array([0.93148303, 0.9236936 , 0.9401986 , 0.91534401, 0.92077974]), 128)\n",
      "(array([0.89515769, 0.91965032, 0.9138828 , 0.88961567, 0.88128994]), 40)\n",
      "(array([0.56186356, 0.60762023, 0.6050676 , 0.63656076, 0.53320597]), 4)\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.logspace(-5, -1, 5):\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91971913, 0.93209643, 0.93525994, 0.90570727, 0.91007427]), 78)\n",
      "(array([0.91485736, 0.93116944, 0.93224535, 0.90325536, 0.90621718]), 67)\n",
      "(array([0.91099258, 0.92999009, 0.9290773 , 0.90102034, 0.90209785]), 57)\n",
      "(array([0.90712796, 0.92836031, 0.92574165, 0.89812118, 0.89791268]), 53)\n",
      "(array([0.90360156, 0.92606697, 0.92194576, 0.8956178 , 0.89283903]), 49)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.004, 0.005, 0.006, 0.007, 0.008]:\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.8413848 , 0.79027596, 0.81367875, 0.82652539, 0.87304321]), 208)\n",
      "(array([0.84624072, 0.81674294, 0.82041365, 0.83061305, 0.87453197]), 197)\n",
      "(array([0.84698813, 0.85629204, 0.83963723, 0.8526459 , 0.88864524]), 150)\n",
      "(array([0.80954862, 0.85234601, 0.78821007, 0.85062299, 0.86319727]), 44)\n",
      "(array([0.38089434, 0.43264064, 0.38766252, 0.40955108, 0.41074173]), 3)\n"
     ]
    }
   ],
   "source": [
    "for alpha in np.logspace(-5, -1, 5):\n",
    "    print(Lasso_select(X1_train,y1_train,alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.91971913, 0.93209643, 0.93525994, 0.90570727, 0.91007427]), 78)\n",
      "(array([0.91485736, 0.93116944, 0.93224535, 0.90325536, 0.90621718]), 67)\n",
      "(array([0.91099258, 0.92999009, 0.9290773 , 0.90102034, 0.90209785]), 57)\n",
      "(array([0.90712796, 0.92836031, 0.92574165, 0.89812118, 0.89791268]), 53)\n",
      "(array([0.90360156, 0.92606697, 0.92194576, 0.8956178 , 0.89283903]), 49)\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.004, 0.005, 0.006, 0.007, 0.008]:\n",
    "    print(Lasso_select(X0_train,y0_train,alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Will try working with 67 and 78 (one-hot encoded) features respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge for robustness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 1}\n",
      "0.916187390828459\n"
     ]
    }
   ],
   "source": [
    "X = X0_train\n",
    "y = y0_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.006, max_iter=10000))),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "\n",
    "param_grid = {'ridge__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ridge__alpha': 1.328828828828829}\n",
      "0.9161880066975602\n"
     ]
    }
   ],
   "source": [
    "X = X0_train\n",
    "y = y0_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.006, max_iter=10000))),\n",
    "                 ('ridge', Ridge())])\n",
    "\n",
    "param_grid = {'ridge__alpha':np.linspace(0.1, 10, 1000)}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Lasso on Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.001}\n",
      "0.8535325152051705\n"
     ]
    }
   ],
   "source": [
    "X = X1_train\n",
    "y = y1_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.008, max_iter=10000))),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "\n",
    "param_grid = {'lasso__alpha':[0.001, 0.1, 1, 10]}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lasso__alpha': 0.002}\n",
      "0.8538154501322366\n"
     ]
    }
   ],
   "source": [
    "X = X1_train\n",
    "y = y1_train\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.008, max_iter=10000))),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "param_grid = {'lasso__alpha':np.linspace(0.001, 0.1, 100)}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, scoring='r2', cv=cv, n_jobs=-1)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now putting it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.006, max_iter=10000))),\n",
    "                 ('ridge', Ridge(alpha=1.33))])\n",
    "\n",
    "pipe.fit(X0_train, y0_train)\n",
    "\n",
    "cluster0_train_predict = pipe.predict(X0_train)\n",
    "cluster0_test_predict = pipe.predict(X0_test)\n",
    "\n",
    "pipe = Pipeline([('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown='ignore'), categorical)], \n",
    "                                            remainder='passthrough')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('selector', SelectFromModel(Lasso(alpha=0.008, max_iter=10000))),\n",
    "                 ('lasso', Lasso(alpha=0.002))])\n",
    "\n",
    "pipe.fit(X1_train, y1_train)\n",
    "\n",
    "cluster1_train_predict = pipe.predict(X1_train)\n",
    "cluster1_test_predict = pipe.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0_train_predict = pd.DataFrame(cluster0_train_predict).rename(columns={0:'prediction'})\n",
    "cluster1_train_predict = pd.DataFrame(cluster1_train_predict).rename(columns={0:'prediction'})\n",
    "cluster0_test_predict = pd.DataFrame(cluster0_test_predict).rename(columns={0:'prediction'})\n",
    "cluster1_test_predict = pd.DataFrame(cluster1_test_predict).rename(columns={0:'prediction'})\n",
    "\n",
    "train_predict = pd.concat([cluster0_train_predict, cluster1_train_predict])\n",
    "test_predict = pd.concat([cluster0_test_predict, cluster1_test_predict])\n",
    "train_target = pd.concat([y0_train, y1_train])\n",
    "test_target = pd.concat([y0_test, y1_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1871\n",
      "624\n",
      "1871\n",
      "624\n"
     ]
    }
   ],
   "source": [
    "print(len(train_predict))\n",
    "print(len(test_predict))\n",
    "print(len(train_target))\n",
    "print(len(test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score is 0.951445140351519\n",
      "Test score is 0.9139302135467522\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score is {r2_score(train_target, train_predict)}')\n",
    "print(f'Test score is {r2_score(test_target, test_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 train score is 0.9447537600032996\n",
      "Cluster 0 test score is 0.9276351864439013\n",
      "\n",
      "\n",
      "Cluster 1 train score is 0.8867757331955866\n",
      "Cluster 1 test score is 0.7564579169331025\n"
     ]
    }
   ],
   "source": [
    "print(f'Cluster 0 train score is {r2_score(y0_train, cluster0_train_predict)}')\n",
    "print(f'Cluster 0 test score is {r2_score(y0_test, cluster0_test_predict)}')\n",
    "print('\\n')\n",
    "print(f'Cluster 1 train score is {r2_score(y1_train, cluster1_train_predict)}')\n",
    "print(f'Cluster 1 test score is {r2_score(y1_test, cluster1_test_predict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSS(y_true, y_predict):\n",
    "    y_true = np.array(y_true)\n",
    "    y_predict = np.array(y_predict)\n",
    "    return np.sum((y_true - y_predict)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSS(y_true):\n",
    "    y_true = np.array(y_true)\n",
    "    return np.sum((y_true - np.mean(y_true))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995299.9938631437\n",
      "272.6363658517055\n",
      "109054.76960286847\n",
      "88.77449859589736\n",
      "149602.0224633217\n",
      "85.91293539289033\n",
      "138003.10151038252\n",
      "74.99676589766047\n",
      "15219.931281359679\n",
      "26.09529960518662\n",
      "14955.100558760892\n",
      "23.619821977309215\n"
     ]
    }
   ],
   "source": [
    "print(RSS(train_target, train_predict))\n",
    "print(TSS(train_target))\n",
    "print(RSS(test_target, test_predict))\n",
    "print(TSS(test_target))\n",
    "print(RSS(y0_train, cluster0_train_predict))\n",
    "print(TSS(y0_train))\n",
    "print(RSS(y1_train, cluster1_train_predict))\n",
    "print(TSS(y1_train))\n",
    "print(RSS(y0_test, cluster0_test_predict))\n",
    "print(TSS(y0_test))\n",
    "print(RSS(y1_test, cluster1_test_predict))\n",
    "print(TSS(y1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a closer look at cluster features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x0_RH',\n",
       " 'Cat__x3_HLS',\n",
       " 'Cat__x5_CulDSac',\n",
       " 'Cat__x5_FR2',\n",
       " 'Cat__x6_Mod',\n",
       " 'Cat__x7_CollgCr',\n",
       " 'Cat__x7_GrnHill',\n",
       " 'Cat__x7_NWAmes',\n",
       " 'Cat__x7_NoRidge',\n",
       " 'Cat__x7_NridgHt',\n",
       " 'Cat__x7_SawyerW',\n",
       " 'Cat__x7_Somerst',\n",
       " 'Cat__x7_StoneBr',\n",
       " 'Cat__x7_Timber',\n",
       " 'Cat__x8_Feedr',\n",
       " 'Cat__x8_Norm',\n",
       " 'Cat__x10_1Fam',\n",
       " 'Cat__x10_Twnhs',\n",
       " 'Cat__x12_Flat',\n",
       " 'Cat__x14_BrkFace',\n",
       " 'Cat__x14_HdBoard',\n",
       " 'Cat__x15_HdBoard',\n",
       " 'Cat__x15_Wd Shng',\n",
       " 'Cat__x17_PConc',\n",
       " 'Cat__x21_N',\n",
       " 'Cat__x24_Basment',\n",
       " 'Cat__x27_New',\n",
       " 'Cat__x29_30',\n",
       " 'Cat__x29_60',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearRemodAdd',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'BsmtQual',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'HeatingQC',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'BsmtFullBath',\n",
       " 'HalfBath',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'PavedDrive',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolQC']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "X = pipe.fit_transform(X0_train)\n",
    "y = y0_train\n",
    "\n",
    "selector = SelectFromModel(Lasso(alpha=0.006, max_iter=10000))\n",
    "selector.fit(X,y)\n",
    "mask0 = selector.get_support()\n",
    "feat_names = pipe.named_steps['transformer'].get_feature_names()\n",
    "names0 = [name for name, boo in zip(feat_names, mask0) if boo]\n",
    "names0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x0_C (all)',\n",
       " 'Cat__x0_RL',\n",
       " 'Cat__x2_IR2',\n",
       " 'Cat__x3_Lvl',\n",
       " 'Cat__x7_BrkSide',\n",
       " 'Cat__x7_Edwards',\n",
       " 'Cat__x7_Greens',\n",
       " 'Cat__x7_MeadowV',\n",
       " 'Cat__x7_Mitchel',\n",
       " 'Cat__x8_Norm',\n",
       " 'Cat__x10_1Fam',\n",
       " 'Cat__x10_Twnhs',\n",
       " 'Cat__x13_WdShngl',\n",
       " 'Cat__x14_AsbShng',\n",
       " 'Cat__x14_BrkFace',\n",
       " 'Cat__x14_PreCast',\n",
       " 'Cat__x15_AsbShng',\n",
       " 'Cat__x15_CBlock',\n",
       " 'Cat__x15_PreCast',\n",
       " 'Cat__x17_BrkTil',\n",
       " 'Cat__x17_PConc',\n",
       " 'Cat__x18_ALQ',\n",
       " 'Cat__x18_GLQ',\n",
       " 'Cat__x18_LwQ',\n",
       " 'Cat__x18_Unf',\n",
       " 'Cat__x21_N',\n",
       " 'Cat__x23_Maj2',\n",
       " 'Cat__x23_Typ',\n",
       " 'Cat__x24_Attchd',\n",
       " 'Cat__x27_Con',\n",
       " 'Cat__x28_Normal',\n",
       " 'Cat__x29_30',\n",
       " 'Cat__x29_160',\n",
       " 'LotArea',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'ExterQual',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinSF2',\n",
       " 'HeatingQC',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'BsmtFullBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageFinish',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'PavedDrive',\n",
       " 'WoodDeckSF',\n",
       " 'ScreenPorch']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "        [\n",
    "            ('transformer', ColumnTransformer([(\"Cat\", OneHotEncoder(handle_unknown = 'ignore'), categorical)], \n",
    "                                                remainder='passthrough')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "X = pipe.fit_transform(X1_train)\n",
    "y = y1_train\n",
    "\n",
    "selector = SelectFromModel(Lasso(alpha=0.006, max_iter=10000))\n",
    "selector.fit(X,y)\n",
    "mask1 = selector.get_support()\n",
    "feat_names = pipe.named_steps['transformer'].get_feature_names()\n",
    "names1 = [name for name, boo in zip(feat_names, mask1) if boo]\n",
    "names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x0_RH',\n",
       " 'Cat__x3_HLS',\n",
       " 'Cat__x5_CulDSac',\n",
       " 'Cat__x5_FR2',\n",
       " 'Cat__x6_Mod',\n",
       " 'Cat__x7_CollgCr',\n",
       " 'Cat__x7_GrnHill',\n",
       " 'Cat__x7_NWAmes',\n",
       " 'Cat__x7_NoRidge',\n",
       " 'Cat__x7_NridgHt',\n",
       " 'Cat__x7_SawyerW',\n",
       " 'Cat__x7_Somerst',\n",
       " 'Cat__x7_StoneBr',\n",
       " 'Cat__x7_Timber',\n",
       " 'Cat__x8_Feedr',\n",
       " 'Cat__x12_Flat',\n",
       " 'Cat__x14_HdBoard',\n",
       " 'Cat__x15_HdBoard',\n",
       " 'Cat__x15_Wd Shng',\n",
       " 'Cat__x24_Basment',\n",
       " 'Cat__x27_New',\n",
       " 'Cat__x29_60',\n",
       " 'LotFrontage',\n",
       " 'MasVnrArea',\n",
       " 'ExterCond',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " 'PoolQC']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names0 if name not in names1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cat__x0_C (all)',\n",
       " 'Cat__x0_RL',\n",
       " 'Cat__x2_IR2',\n",
       " 'Cat__x3_Lvl',\n",
       " 'Cat__x7_BrkSide',\n",
       " 'Cat__x7_Edwards',\n",
       " 'Cat__x7_Greens',\n",
       " 'Cat__x7_MeadowV',\n",
       " 'Cat__x7_Mitchel',\n",
       " 'Cat__x13_WdShngl',\n",
       " 'Cat__x14_AsbShng',\n",
       " 'Cat__x14_PreCast',\n",
       " 'Cat__x15_AsbShng',\n",
       " 'Cat__x15_CBlock',\n",
       " 'Cat__x15_PreCast',\n",
       " 'Cat__x17_BrkTil',\n",
       " 'Cat__x18_ALQ',\n",
       " 'Cat__x18_GLQ',\n",
       " 'Cat__x18_LwQ',\n",
       " 'Cat__x18_Unf',\n",
       " 'Cat__x23_Maj2',\n",
       " 'Cat__x23_Typ',\n",
       " 'Cat__x24_Attchd',\n",
       " 'Cat__x27_Con',\n",
       " 'Cat__x28_Normal',\n",
       " 'Cat__x29_160',\n",
       " 'YearBuilt',\n",
       " 'BsmtCond',\n",
       " 'LowQualFinSF',\n",
       " 'FullBath',\n",
       " 'BedroomAbvGr',\n",
       " 'GarageFinish',\n",
       " 'WoodDeckSF']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names1 if name not in names0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
