{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22704ada",
   "metadata": {},
   "source": [
    "# RF including Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8011ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper import * \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "70ee685e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80224b0",
   "metadata": {},
   "source": [
    "# Import data and clean with wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "201c299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data\n",
    "housing = pd.read_csv('Ames_Housing_Price_Data.csv', index_col=0,low_memory = False)\n",
    "# data processing\n",
    "train, test = helper.data_processing_wrapper(housing,\n",
    "                                               num_to_cat_list = ['MSSubClass','MoSold'],\n",
    "                                             remove_PID = False\n",
    "                                        )\n",
    "\n",
    "# feature engineering wrapper\n",
    "train, test = feature_engineering_wrapper(train, test)\n",
    "\n",
    "# importing school feature\n",
    "schools = pd.read_csv('schoolFeatures.csv',index_col = 0)\n",
    "school_keep = [\n",
    "    'PID',\n",
    "    'closestSchool'\n",
    "]\n",
    "schools = schools[school_keep]\n",
    "\n",
    "# merge school feature onto original data set.\n",
    "train = train.merge(schools, how = 'left', left_on = 'PID', right_on = 'PID')\n",
    "test = test.merge(schools, how = 'left', left_on = 'PID', right_on = 'PID')\n",
    "\n",
    "train = train.dropna(subset=['closestSchool'])\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "test = test.dropna(subset=['closestSchool'])\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c4a8ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#housing started out with 81 columns (2580 rows)\n",
    "#feature engineering - ended up with 129 columns (including PID and SalePrice)-- (added 48 new columns) (2477 rows between train and test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627bae01",
   "metadata": {},
   "source": [
    "# Split into predictors and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "de532809",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = train.copy()\n",
    "test_raw = test.copy()\n",
    "\n",
    "train_X = train_raw.drop(['SalePrice','PID'],axis='columns')\n",
    "train_y = np.log(train_raw['SalePrice'])\n",
    "test_X = test_raw.drop(['SalePrice','PID'],axis='columns')\n",
    "test_y = np.log(test_raw['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8a6bc1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_log = train_y.rename('LogSalePrice')\n",
    "test_y_log = test_y.rename('LogSalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6af6d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = train_X.select_dtypes(['object']).columns.to_list()\n",
    "num_feats = train_X.select_dtypes(['int','float']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "79a88878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_feats) # 32 categorical features (43 originally in housing dataset)\n",
    "len(num_feats) #95 numeric features (38 originally)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e43289",
   "metadata": {},
   "source": [
    "# Dummify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f467c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing / Dummification\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('tf1',OneHotEncoder(sparse=False, handle_unknown='ignore'), cat_feats)],remainder='passthrough')\n",
    "\n",
    "train_X_transformed = preprocessor.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1c7024d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get one-hot encoded column names \n",
    "columns_transformed = preprocessor.named_transformers_['tf1'].get_feature_names(input_features= cat_feats)\n",
    "new_columns = list(columns_transformed)+num_feats\n",
    "\n",
    "#Place one-hot encoded train X into dataframe \n",
    "train_X_transformed = pd.DataFrame(train_X_transformed,columns=new_columns)\n",
    "\n",
    "#Repeat for test X \n",
    "test_X_transformed = preprocessor.transform(test_X)\n",
    "test_X_transformed = pd.DataFrame(test_X_transformed,columns=new_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327d976",
   "metadata": {},
   "source": [
    "# Filter down Features Based off of LASSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5ba45d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features selected by LASSO model (non-zero coefficients)\n",
    "coef_df = pd.read_csv('lasso_coef.csv',index_col=0) #Hayden shared this on Slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "31907745",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = list(coef_df['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "45c3ebb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of LASSO selected features: 140\n"
     ]
    }
   ],
   "source": [
    "print('Number of LASSO selected features: '+ str(len(selected_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ed587091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total features after preprocessing: 323\n"
     ]
    }
   ],
   "source": [
    "print('Number of total features after preprocessing: ' + str(len(train_X_transformed.columns.to_list())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ab572f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter dataframes down to the select_features \n",
    "train_X= train_X_transformed[selected_features]\n",
    "test_X = test_X_transformed[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685c08a",
   "metadata": {},
   "source": [
    "# Random Forest Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f1688bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fb29e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. No Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "63e021a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8ec30cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(train_X, train_y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7c268395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Val score:  [0.92803767 0.92461461 0.9188618 ]\n",
      "Cross Val score mean:  0.9238380290736682\n",
      "Train score:  0.98945671606562\n",
      "Test score:  0.8984127748003494\n"
     ]
    }
   ],
   "source": [
    "print('Cross Val score: ', cross_val_score(rf, train_X, train_y_log, cv=3))\n",
    "print('Cross Val score mean: ', cross_val_score(rf, train_X, train_y_log, cv=3).mean())\n",
    "print('Train score: ',rf.score(train_X,train_y_log))\n",
    "print('Test score: ',rf.score(test_X,test_y_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7781231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. With Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "312488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [100,200,400,600,1000]\n",
    "# Number of features to consider at every split\n",
    "max_features = list(range(10,140,20)) + ['auto','sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = list(range(10,111,10)) + ['None']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "47637a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 400, 600, 1000],\n",
       " 'max_features': [10, 30, 50, 70, 90, 110, 130, 'auto', 'sqrt'],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 'None'],\n",
       " 'min_samples_split': [2, 5, 10],\n",
       " 'min_samples_leaf': [1, 10],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df0ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
